{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src = logo-IJCLab-1.png width=250, style=\"padding: 10px\"> \n",
    "<b>Query information on tracts and patchs from objects table </b> <br>\n",
    "Last verified to run on 2022-10-12 with LSST Science Pipelines release w_2022_40 <br>\n",
    "Contact authors: Sylvie Dagoret-Campagne (DP0 Delegate) <br>\n",
    "Target audience: DP0 delegates member <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "The goal is to localize some big structures in tracts by using a Top - Down approach, starting from a tract then selecting manually a redshift slice with Holoview tool.\n",
    "The density of sources is filtered by a KDE gaussian kernel to emphasize the LSS structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general python packages\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pandas.testing import assert_frame_equal\n",
    "import os\n",
    "import errno\n",
    "import shutil\n",
    "import getpass\n",
    "\n",
    "# Import the Rubin TAP service utilities\n",
    "from lsst.rsp import get_tap_service, retrieve_query\n",
    "\n",
    "# LSST Science Pipelines (Stack) packages\n",
    "import lsst.daf.butler as dafButler\n",
    "import lsst.afw.display as afwDisplay\n",
    "import lsst.geom as geom\n",
    "import lsst.afw.coord as afwCoord\n",
    "afwDisplay.setDefaultBackend('matplotlib')\n",
    "\n",
    "#\n",
    "from lsst import skymap\n",
    "\n",
    "# Astropy\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# Bokeh for interactive visualization\n",
    "import bokeh\n",
    "from bokeh.io import output_file, output_notebook, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import ColumnDataSource, CDSView, GroupFilter, HoverTool\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import streams, opts\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from holoviews.operation.datashader import datashade, dynspread\n",
    "from holoviews.plotting.util import process_cmap\n",
    "\n",
    "import datashader as dsh\n",
    "\n",
    "\n",
    "# Set the maximum number of rows to display from pandas\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "\n",
    "# Set the holoviews plotting library to be bokeh\n",
    "# You will see the holoviews + bokeh icons displayed when the library is loaded successfully\n",
    "hv.extension('bokeh', 'matplotlib')\n",
    "\n",
    "\n",
    "# Display bokeh plots inline in the notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What versions of bokeh and holoviews nd datashader are we working with?\n",
    "# This is important when referring to online documentation as\n",
    "# APIs can change between versions.\n",
    "print(\"Bokeh version: \" + bokeh.__version__)\n",
    "print(\"Holoviews version: \" + hv.__version__)\n",
    "print(\"Datashader version: \" + dsh.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow for matplotlib to create inline plots in our notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt      # imports matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import warnings                      # imports the warnings library\n",
    "import gc                            # imports python's garbage collector\n",
    "\n",
    "# Ignore warnings\n",
    "from astropy.units import UnitsWarning\n",
    "warnings.simplefilter(\"ignore\", category=UnitsWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some plotting defaults:\n",
    "\n",
    "params = {'axes.labelsize': 28,\n",
    "          'font.size': 24,\n",
    "          'legend.fontsize': 14,\n",
    "          'xtick.major.width': 3,\n",
    "          'xtick.minor.width': 2,\n",
    "          'xtick.major.size': 12,\n",
    "          'xtick.minor.size': 6,\n",
    "          'xtick.direction': 'in',\n",
    "          'xtick.top': True,\n",
    "          'lines.linewidth': 3,\n",
    "          'axes.linewidth': 3,\n",
    "          'axes.labelweight': 3,\n",
    "          'axes.titleweight': 3,\n",
    "          'ytick.major.width': 3,\n",
    "          'ytick.minor.width': 2,\n",
    "          'ytick.major.size': 12,\n",
    "          'ytick.minor.size': 6,\n",
    "          'ytick.direction': 'in',\n",
    "          'ytick.right': True,\n",
    "          'figure.figsize': [10, 6],\n",
    "          'figure.facecolor': 'White'\n",
    "          }\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import FlatLambdaCDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_figure(fig):\n",
    "    \"\"\"Remove a figure to reduce memory footprint. \"\"\"\n",
    "    # get the axes and clear their images\n",
    "    for ax in fig.get_axes():\n",
    "        for im in ax.get_images():\n",
    "            im.remove()\n",
    "    fig.clf()      # clear the figure\n",
    "    plt.close(fig) # close the figure\n",
    "    gc.collect()   # call the garbage collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What version of the Stack are we using?\n",
    "! echo $IMAGE_DESCRIPTION\n",
    "! eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Notebook Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 setup pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# username\n",
    "myusername=getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary folders if necessary\n",
    "NBDIR       = 'survpropmap'                       # relative path for this notebook output\n",
    "TMPTOPDIR   = \"/scratch\"                          # always write some output in /scratch, never in user HOME \n",
    "TMPUSERDIR  = os.path.join(TMPTOPDIR,myusername)  # defines the path of user outputs in /scratch \n",
    "TMPNBDIR    = os.path.join(TMPUSERDIR,NBDIR)      # output path for this particular notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user temporary directory\n",
    "if not os.path.isdir(TMPUSERDIR):\n",
    "    try:\n",
    "        os.mkdir(TMPUSERDIR)\n",
    "    except:\n",
    "        raise OSError(f\"Can't create destination directory {TMPUSERDIR}!\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create this notebook temporary directory\n",
    "if not os.path.isdir(TMPNBDIR):\n",
    "    try:\n",
    "        os.mkdir(TMPNBDIR)\n",
    "    except:\n",
    "        raise OSError(f\"Can't create destination directory {TMPNBDIR}!\" ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Defines steering flags and parameters\n",
    "\n",
    "The Output of the query may be saved in a file to speed up the nb if run more than one time.\n",
    "By defaults all the following flags are set False : no query output is saved in file.\n",
    "To speed-up the demo, the presenter may keep some of those flags True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_WRITE_DATAFRAMEONDISK  = True   # Select if query output will be saved on disk\n",
    "FLAG_READ_DATAFRAMEFROMDISK = True   # Select if the query can be read from disk if it exists\n",
    "FLAG_CLEAN_DATAONDISK       = False  # Select if the output queries saved in file will be cleaned at the end of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create the Rubin TAP Service client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an instance of the TAP service\n",
    "service = get_tap_service()\n",
    "assert service is not None\n",
    "assert service.baseurl == \"https://data.lsst.cloud/api/tap\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Work at patch level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGLIM = 21.0\n",
    "RAMIN = 48.57 \n",
    "RAMAX = 75.24\n",
    "DECMIN = -44.63 \n",
    "DECMAX = -26.78 \n",
    "\n",
    "RIGHT_ASCENSION_CENTER = (RAMIN+RAMAX) /2.\n",
    "DECLINATION_CENTER = (DECMIN+DECMAX) /2.\n",
    "WIDTH = RAMAX - RAMIN \n",
    "HEIGHT = DECMAX - DECMIN\n",
    "\n",
    "VERTEXES = str(RAMIN) + \",\" + str(DECMIN) + \",\" + str(RAMAX) + \",\" + str(DECMIN) + \",\" + str(RAMAX) +\",\" + str(DECMAX) + \\\n",
    "\",\" + str(RAMIN) +\",\" + str(DECMAX)\n",
    "VERTEXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_adql_query = \"SELECT coord_ra, coord_dec \" + \\\n",
    "                \"FROM dp02_dc2_catalogs.Object \" + \\\n",
    "                \"WHERE CONTAINS(POINT('ICRS', coord_ra, coord_dec), \" + \\\n",
    "                \"POLYGON('ICRS',\" + VERTEXES + \" )) = 1 \" + \\\n",
    "                \"AND r_extendedness = 1 \" \\\n",
    "                \"AND detect_isPrimary = 1 \" \\\n",
    "                \"AND scisql_nanojanskyToAbMag(r_cModelFlux) < \" +str(MAGLIM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_adql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_result=f'sources_result.pkl'\n",
    "fullfilename_result=os.path.join(TMPNBDIR,filename_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAG_READ_DATAFRAMEFROMDISK and os.path.exists(fullfilename_result):\n",
    "    sql_result = pd.read_pickle(fullfilename_result)\n",
    "    source_data  = sql_result\n",
    "else:\n",
    "    # Create and submit the job. This step does not run the query yet\n",
    "    job = service.submit_job(my_adql_query,maxrec=5_000_000)\n",
    "    # Get the job URL\n",
    "    print('Job URL is', job.url)\n",
    "\n",
    "    # Get the job phase. It will be pending as we have not yet started the job\n",
    "    print('Job phase is', job.phase)\n",
    "    \n",
    "    # Run the job. You will see that the the cell completes executing,\n",
    "    # even though the query is still running\n",
    "    job.run()\n",
    "    \n",
    "    # Use this to tell python to wait for the job to finish if\n",
    "    # you don't want to run anything else while waiting\n",
    "    # The cell will continue executing until the job is finished\n",
    "    job.wait(phases=['COMPLETED', 'ERROR'])\n",
    "    print('Job phase is', job.phase)\n",
    "    \n",
    "    # A usefull funtion to raise an exception if there was a problem with the query\n",
    "    job.raise_if_error()\n",
    "    \n",
    "    # Once the job completes successfully, you can fetch the results\n",
    "    async_tract_data = job.fetch_result()\n",
    "    \n",
    "    source_data = async_tract_data.to_table().to_pandas()\n",
    "    \n",
    "    \n",
    "if FLAG_WRITE_DATAFRAMEONDISK:\n",
    "    source_data.to_pickle(fullfilename_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l $TMPNBDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) 2D histogram view with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=source_data[\"coord_ra\"]\n",
    "y=source_data[\"coord_dec\"]\n",
    "xmin=x.min()\n",
    "xmax=x.max()\n",
    "ymin=y.min()\n",
    "ymax=y.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, xedges, yedges = np.histogram2d(x, y, bins=(1000, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm = Normalize(vmin=0, vmax=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "img=ax.imshow(H.T,origin=\"lower\",extent=(xmin,xmax,ymin,ymax),cmap=\"jet\")\n",
    "plt.colorbar(img, ax=ax)\n",
    "ax.set_aspect('auto')\n",
    "ax.set_xlabel(\"RA (deg)\")\n",
    "ax.set_ylabel(\"DEC (deg)\")\n",
    "ax.set_title(f\"sources (matplotlib image, histo2D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_figure(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(np.ravel(H),bins=50,range=(0,51),color='b')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View with holoview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_opts = dict(height=350, width=450, \n",
    "                xaxis=\"bottom\", \n",
    "                padding = 0.01, fontsize={'title': '12pt'},\n",
    "                colorbar=True, toolbar='right', show_grid=True,\n",
    "                title= f\"Objects for SPM\",\n",
    "                xlabel=\"RA\",\n",
    "                ylabel=\"DEC\",\n",
    "                tools=['hover']\n",
    "               )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipHT=np.flipud(H.T)\n",
    "img=hv.Image(flipHT,bounds=(x.min(),y.min(),x.max(),y.max())).opts(cmap=\"jet\",title=f\"Objects\",xlabel=\"RA\",ylabel=\"DEC\").opts(**img_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterize(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean file if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAG_CLEAN_DATAONDISK:\n",
    "    if os.path.isdir(TMPNBDIR):\n",
    "        try:\n",
    "            shutil.rmtree(TMPNBDIR)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s : %s\" % (TMPNBDIR, e.strerror)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
